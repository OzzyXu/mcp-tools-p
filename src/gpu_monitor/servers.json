{
  "servers": [
    {
      "id": "gpu01",
      "hostname": "gpu01.cluster.local",
      "description": "Primary training server"
    },
    {
      "id": "gpu02", 
      "hostname": "gpu02.cluster.local",
      "description": "Secondary training server"
    },
    {
      "id": "gpu03",
      "hostname": "gpu03.cluster.local", 
      "description": "Inference server"
    }
  ],
  "settings": {
    "cache_ttl": 30,
    "ssh_timeout": 5,
    "max_concurrent": 4
  }
}
